#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Prismç³»ç»Ÿæµ‹è¯•æœåŠ¡å™¨ - ç®€åŒ–ç‰ˆæœ¬
ç”¨äºéªŒè¯æ ¸å¿ƒåŠŸèƒ½
"""

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import Dict, Any, List, Optional
import asyncio
from datetime import datetime
import json
import redis
import uuid
import os
import shutil
from loguru import logger
import aiohttp

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Prism Test System",
    version="1.0.0",
    description="Prismè‚¡ç¥¨åˆ†ææ–‡ç« ç”Ÿæˆç³»ç»Ÿæµ‹è¯•ç‰ˆ"
)

# CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/static", StaticFiles(directory="frontend"), name="static")
app.mount("/assets", StaticFiles(directory="frontend/assets"), name="assets")

# æ ¹è·¯ç”± - ç›´æ¥è®¿é—®å‰ç«¯
@app.get("/")
async def read_root():
    """é‡å®šå‘åˆ°å‰ç«¯é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('frontend/index.html')

# ä»ªè¡¨ç›˜è·¯ç”±
@app.get("/dashboard")
async def dashboard():
    """è®¿é—®ä»ªè¡¨ç›˜é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('frontend/dashboard.html')

@app.get("/dashboard_v2")
async def dashboard_v2():
    """è®¿é—®ä¼˜åŒ–åçš„ä»ªè¡¨ç›˜é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('frontend/dashboard_v2.html')

@app.get("/expert")
async def expert_dashboard():
    """è®¿é—®ä¸“å®¶åˆ†æä»ªè¡¨ç›˜é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('frontend/expert_dashboard.html')

@app.get("/upload")
async def upload_page():
    """è®¿é—®æ–‡ä»¶ä¸Šä¼ é¡µé¢"""
    from fastapi.responses import FileResponse
    return FileResponse('frontend/upload.html')

# æ•°æ®æ¨¡å‹
class ArticleRequest(BaseModel):
    stock_code: str
    article_styles: Optional[List[str]] = None

class TaskResponse(BaseModel):
    task_id: str
    status: str
    message: str

# å…¨å±€å˜é‡å­˜å‚¨ä»»åŠ¡çŠ¶æ€
task_storage = {}

# è‚¡ç¥¨æ•°æ®ç¼“å­˜
stock_data_cache = {}

# å¥åº·æ£€æŸ¥
@app.get("/health")
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥Redisè¿æ¥
        r = redis.Redis(host='localhost', port=6379, db=0)
        r.ping()
        redis_status = "connected"
    except:
        redis_status = "disconnected"
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "services": {
            "redis": redis_status,
            "database": "simulated"
        }
    }

# çœŸå®è‚¡ç¥¨æ•°æ®è·å–
@app.get("/api/stocks/{stock_code}/data")
async def get_stock_data(stock_code: str, data_type: Optional[str] = None):
    """è·å–è‚¡ç¥¨æ•°æ® (çœŸå®æ•°æ®)"""
    
    # éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
    if not stock_code or len(stock_code) < 6:
        raise HTTPException(status_code=400, detail="è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯")
    
    try:
        # è·å–çœŸå®è‚¡ç¥¨æ•°æ®
        real_data = await fetch_real_stock_data(stock_code)
        
        if data_type:
            if data_type in real_data:
                return real_data[data_type]
            else:
                raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ•°æ®ç±»å‹")
        
        return real_data
        
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {stock_code} - {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}")

async def fetch_real_stock_data(stock_code: str) -> Dict[str, Any]:
    """ä»çœŸå®APIè·å–è‚¡ç¥¨æ•°æ®"""
    base_url = "http://35.77.54.203:3003"
    
    async with aiohttp.ClientSession() as session:
        try:
            # è·å–åŸºæœ¬é¢æ•°æ®
            async with session.get(f"{base_url}/stocks/{stock_code}/analysis/fundamental") as response:
                if response.status == 200:
                    fundamental_raw = await response.json()
                else:
                    fundamental_raw = {}
            
            # è·å–æŠ€æœ¯é¢æ•°æ®
            async with session.get(f"{base_url}/stocks/{stock_code}/analysis/technical") as response:
                if response.status == 200:
                    technical_raw = await response.json()
                else:
                    technical_raw = {}
            
            # å¤„ç†åŸºæœ¬é¢æ•°æ®
            basic_info = fundamental_raw.get("basic_info", {})
            fundamental_data = {
                "source": "fundamental_analysis",
                "stock_code": stock_code,
                "stock_name": fundamental_raw.get("stock_name", "æœªçŸ¥è‚¡ç¥¨"),
                "current_price": basic_info.get("æœ€æ–°", 0),
                "market_cap": basic_info.get("æ€»å¸‚å€¼", 0),
                "circulating_market_cap": basic_info.get("æµé€šå¸‚å€¼", 0),
                "pe_ratio": 0,  # åŸºæœ¬é¢æ•°æ®ä¸­æ²¡æœ‰PEï¼Œä»æŠ€æœ¯é¢è·å–
                "industry": basic_info.get("è¡Œä¸š", "æœªçŸ¥è¡Œä¸š"),
                "listing_date": basic_info.get("ä¸Šå¸‚æ—¶é—´", ""),
                "total_shares": basic_info.get("æ€»è‚¡æœ¬", 0),
                "circulating_shares": basic_info.get("æµé€šè‚¡", 0),
                "updated_at": datetime.now().isoformat()
            }
            
            # å¤„ç†æŠ€æœ¯é¢æ•°æ® - æå–æ›´å¤šæŒ‡æ ‡
            real_time_data = technical_raw.get("real_time_data", {})
            analysis_data = technical_raw.get("analysis_data", {})
            k_line_data = technical_raw.get("k_line_data", [])
            
            # è·å–æœ€æ–°ä¸€å¤©çš„Kçº¿æ•°æ®
            latest_k = k_line_data[-1] if k_line_data else {}
            
            technical_data = {
                "source": "technical_analysis", 
                "stock_code": stock_code,
                "analysis_type": technical_raw.get("analysis_type", "æŠ€æœ¯åˆ†æ"),
                "current_price": real_time_data.get("æœ€æ–°", analysis_data.get("current_price", 0)),
                "price_change": analysis_data.get("price_change", real_time_data.get("æ¶¨è·Œ", 0)),
                "price_change_pct": analysis_data.get("price_change_pct", real_time_data.get("æ¶¨å¹…", 0)),
                "volume": analysis_data.get("volume", real_time_data.get("æ€»æ‰‹", 0)),
                "turnover": real_time_data.get("é‡‘é¢", 0),
                "turnover_rate": analysis_data.get("turnover_rate", real_time_data.get("æ¢æ‰‹", 0)),
                "volume_ratio": real_time_data.get("é‡æ¯”", 0),
                "pe_ratio": technical_raw.get("technical_indicators", {}).get("å¸‚ç›ˆç‡", 0),
                "pb_ratio": technical_raw.get("technical_indicators", {}).get("å¸‚å‡€ç‡", 0),
                "high_price": analysis_data.get("recent_high", real_time_data.get("æœ€é«˜", latest_k.get("æœ€é«˜", 0))),
                "low_price": analysis_data.get("recent_low", real_time_data.get("æœ€ä½", latest_k.get("æœ€ä½", 0))),
                "open_price": real_time_data.get("ä»Šå¼€", latest_k.get("å¼€ç›˜", 0)),
                "prev_close": real_time_data.get("æ˜¨æ”¶", 0),
                "limit_up": real_time_data.get("æ¶¨åœ", 0),
                "limit_down": real_time_data.get("è·Œåœ", 0),
                "bid_ask_spread": {
                    "buy_1": real_time_data.get("buy_1", 0),
                    "buy_1_vol": real_time_data.get("buy_1_vol", 0),
                    "sell_1": real_time_data.get("sell_1", 0),
                    "sell_1_vol": real_time_data.get("sell_1_vol", 0),
                },
                "market_mood": {
                    "å¤–ç›˜": real_time_data.get("å¤–ç›˜", 0),
                    "å†…ç›˜": real_time_data.get("å†…ç›˜", 0),
                },
                "recent_performance": {
                    "æŒ¯å¹…": latest_k.get("æŒ¯å¹…", 0) if latest_k else 0,
                    "æ¶¨è·Œå¹…": latest_k.get("æ¶¨è·Œå¹…", 0) if latest_k else 0,
                },
                "indicators": technical_raw.get("technical_indicators", {}),
                "signals": technical_raw.get("trading_signals", []),
                "trend": determine_trend(k_line_data[-10:] if len(k_line_data) >= 10 else k_line_data),
                "updated_at": datetime.now().isoformat()
            }
            
            # ä»åŸºæœ¬é¢æ•°æ®æå–è´¢åŠ¡æŒ‡æ ‡
            financial_indicators = fundamental_raw.get("financial_indicators", [])
            
            # æå–ä¸»è¦è´¢åŠ¡æ•°æ®
            revenue_data = {}
            profit_data = {}
            roe_data = {}
            eps_data = {}
            cash_flow_data = {}
            
            for indicator in financial_indicators[:10]:  # å–å‰10ä¸ªä¸»è¦æŒ‡æ ‡
                indicator_name = indicator.get("æŒ‡æ ‡", "")
                if indicator_name == "è¥ä¸šæ€»æ”¶å…¥":
                    for quarter in ["20250630", "20250331", "20241231", "20240930", "20240630"]:
                        if quarter in indicator and indicator[quarter]:
                            revenue_data[quarter] = indicator[quarter]
                elif indicator_name == "å½’æ¯å‡€åˆ©æ¶¦":
                    for quarter in ["20250630", "20250331", "20241231", "20240930", "20240630"]:
                        if quarter in indicator and indicator[quarter]:
                            profit_data[quarter] = indicator[quarter]
                elif indicator_name == "å‡€èµ„äº§æ”¶ç›Šç‡(ROE)":
                    for quarter in ["20250630", "20250331", "20241231", "20240930"]:
                        if quarter in indicator and indicator[quarter]:
                            roe_data[quarter] = indicator[quarter]
                elif indicator_name == "åŸºæœ¬æ¯è‚¡æ”¶ç›Š":
                    for quarter in ["20250630", "20250331", "20241231", "20240930"]:
                        if quarter in indicator and indicator[quarter]:
                            eps_data[quarter] = indicator[quarter]
                elif indicator_name == "ç»è¥ç°é‡‘æµé‡å‡€é¢":
                    for quarter in ["20250630", "20250331", "20241231", "20240930"]:
                        if quarter in indicator and indicator[quarter]:
                            cash_flow_data[quarter] = indicator[quarter]
            
            financial_data = {
                "source": "financial_data",
                "stock_code": stock_code,
                "revenue_data": revenue_data,
                "profit_data": profit_data,
                "roe_data": roe_data,
                "eps_data": eps_data,
                "cash_flow_data": cash_flow_data,
                "financial_indicators": financial_indicators[:8],  # å–å‰8ä¸ªä¸»è¦æŒ‡æ ‡
                "updated_at": datetime.now().isoformat()
            }
            
            # æ¨¡æ‹Ÿå¸‚åœºæƒ…ç»ªæ•°æ® (åŸºäºæŠ€æœ¯é¢æ•°æ®)
            outer_inner_ratio = 0.5  # ä¸­æ€§
            if real_time_data.get("å¤–ç›˜", 0) and real_time_data.get("å†…ç›˜", 0):
                total_trade = real_time_data["å¤–ç›˜"] + real_time_data["å†…ç›˜"]
                if total_trade > 0:
                    outer_inner_ratio = real_time_data["å¤–ç›˜"] / total_trade
            
            sentiment_score = min(max((outer_inner_ratio - 0.3) * 2, 0), 1)  # 0-1èŒƒå›´
            
            sentiment_data = {
                "source": "market_sentiment",
                "stock_code": stock_code,
                "sentiment_score": sentiment_score,
                "news_sentiment": "positive" if sentiment_score > 0.6 else ("negative" if sentiment_score < 0.4 else "neutral"),
                "market_mood": "å¤šå¤´æ°”æ°›" if outer_inner_ratio > 0.55 else ("ç©ºå¤´æ°”æ°›" if outer_inner_ratio < 0.45 else "ç›˜æ•´æ°”æ°›"),
                "volume_analysis": "æ”¾é‡" if real_time_data.get("é‡æ¯”", 0) > 1.5 else ("ç¼©é‡" if real_time_data.get("é‡æ¯”", 0) < 0.8 else "æ­£å¸¸"),
                "analyst_ratings": {"buy": 3, "hold": 2, "sell": 1},  # æ¨¡æ‹Ÿæ•°æ®
                "updated_at": datetime.now().isoformat()
            }
            
            return {
                "stock_code": stock_code,
                "collected_at": datetime.now().isoformat(),
                "fundamental": fundamental_data,
                "technical": technical_data,
                "financial": financial_data,
                "sentiment": sentiment_data
            }
            
        except Exception as e:
            logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¼‚å¸¸: {stock_code} - {e}")
            raise

# AIåˆ†æç¼“å­˜å­˜å‚¨ (æ¯æ—¥ç¼“å­˜)
daily_ai_cache = {}

def get_cache_key(stock_code: str, analysis_type: str) -> str:
    """ç”Ÿæˆæ¯æ—¥ç¼“å­˜é”®"""
    today = datetime.now().strftime("%Y-%m-%d")
    return f"{stock_code}_{analysis_type}_{today}"

def is_cache_valid(cache_key: str) -> bool:
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
    return cache_key in daily_ai_cache

async def financial_statement_expert(stock_code: str, financial_data: dict) -> dict:
    """è´¢æŠ¥åˆ†æä¸“å®¶ - ä¸“ä¸šè´¢åŠ¡æ¼æ´æ£€æµ‹"""
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = get_cache_key(stock_code, "financial_expert")
    if is_cache_valid(cache_key):
        logger.info(f"ğŸ”„ ä½¿ç”¨è´¢æŠ¥ä¸“å®¶ç¼“å­˜: {stock_code}")
        return daily_ai_cache[cache_key]
    
    try:
        # è·å–è´¢åŠ¡æŒ‡æ ‡
        financial_indicators = financial_data.get("financial_indicators", [])
        revenue_data = financial_data.get("revenue_data", {})
        profit_data = financial_data.get("profit_data", {})
        cash_flow_data = financial_data.get("cash_flow_data", {})
        
        # è´¢æŠ¥å¼‚å¸¸æ£€æµ‹é€»è¾‘
        red_flags = []
        quality_score = 100
        
        # 1. æ”¶å…¥ä¸åˆ©æ¶¦å¢é•¿ç‡åŒ¹é…åº¦æ£€æµ‹
        if revenue_data and profit_data:
            recent_quarters = sorted(revenue_data.keys(), reverse=True)[:2]
            if len(recent_quarters) >= 2:
                q1, q2 = recent_quarters[0], recent_quarters[1]
                if revenue_data[q1] and revenue_data[q2] and profit_data.get(q1) and profit_data.get(q2):
                    revenue_growth = (revenue_data[q1] - revenue_data[q2]) / revenue_data[q2] * 100
                    profit_growth = (profit_data[q1] - profit_data[q2]) / profit_data[q2] * 100
                    
                    if abs(revenue_growth - profit_growth) > 30:
                        red_flags.append(f"âš ï¸ æ”¶å…¥å¢é•¿ç‡({revenue_growth:.1f}%)ä¸åˆ©æ¶¦å¢é•¿ç‡({profit_growth:.1f}%)ä¸¥é‡ä¸åŒ¹é…")
                        quality_score -= 15
        
        # 2. ç°é‡‘æµä¸åˆ©æ¶¦åŒ¹é…åº¦æ£€æµ‹
        if cash_flow_data and profit_data:
            recent_quarter = max(cash_flow_data.keys()) if cash_flow_data else None
            if recent_quarter and recent_quarter in profit_data:
                cash_flow = cash_flow_data[recent_quarter] / 100000000  # è½¬ä¸ºäº¿å…ƒ
                profit = profit_data[recent_quarter] / 100000000  # è½¬ä¸ºäº¿å…ƒ
                if profit > 0:
                    cash_profit_ratio = cash_flow / profit
                    if cash_profit_ratio < 0.5:
                        red_flags.append(f"ğŸš¨ ç»è¥ç°é‡‘æµ({cash_flow:.1f}äº¿)è¿œä½äºå‡€åˆ©æ¶¦({profit:.1f}äº¿)ï¼Œç°é‡‘è´¨é‡å ªå¿§")
                        quality_score -= 20
                    elif cash_profit_ratio < 0.8:
                        red_flags.append(f"âš ï¸ ç»è¥ç°é‡‘æµ({cash_flow:.1f}äº¿)ä½äºå‡€åˆ©æ¶¦({profit:.1f}äº¿)ï¼Œéœ€å…³æ³¨")
                        quality_score -= 10
        
        # 3. åº”æ”¶è´¦æ¬¾åˆ†æï¼ˆåŸºäºè¥ä¸šæ”¶å…¥æ¨ç®—ï¼‰
        if revenue_data:
            recent_quarters = sorted(revenue_data.keys(), reverse=True)[:4]  # æœ€è¿‘4ä¸ªå­£åº¦
            if len(recent_quarters) >= 2:
                q1_revenue = revenue_data[recent_quarters[0]] / 100000000
                q4_revenue_total = sum(revenue_data.get(q, 0) for q in recent_quarters) / 100000000
                # å‡è®¾åº”æ”¶è´¦æ¬¾å è¥ä¸šæ”¶å…¥æ¯”ä¾‹è¶…è¿‡20%ä¸ºå¼‚å¸¸
                if q1_revenue > 0:
                    estimated_ar_ratio = min((q4_revenue_total * 0.15) / q1_revenue, 0.3)
                    if estimated_ar_ratio > 0.2:
                        red_flags.append(f"âš ï¸ æ¨ç®—åº”æ”¶è´¦æ¬¾å æ”¶å…¥æ¯”ä¾‹åé«˜({estimated_ar_ratio*100:.1f}%)ï¼Œéœ€å…³æ³¨å›æ¬¾èƒ½åŠ›")
                        quality_score -= 10
        
        # 4. æ¯›åˆ©ç‡ç¨³å®šæ€§æ£€æµ‹
        if revenue_data and len(financial_indicators) > 2:
            cost_indicator = next((item for item in financial_indicators if "è¥ä¸šæˆæœ¬" in item.get("æŒ‡æ ‡", "")), None)
            if cost_indicator:
                gross_margins = []
                for quarter in sorted(revenue_data.keys(), reverse=True)[:4]:
                    if quarter in revenue_data and quarter in cost_indicator:
                        revenue = revenue_data[quarter]
                        cost = cost_indicator.get(quarter, 0)
                        if revenue and cost and revenue > cost:
                            margin = (revenue - cost) / revenue * 100
                            gross_margins.append(margin)
                
                if len(gross_margins) >= 3:
                    margin_std = sum((x - sum(gross_margins)/len(gross_margins))**2 for x in gross_margins) ** 0.5
                    if margin_std > 5:
                        red_flags.append(f"âš ï¸ æ¯›åˆ©ç‡æ³¢åŠ¨è¾ƒå¤§(æ ‡å‡†å·®{margin_std:.1f}%)ï¼Œç›ˆåˆ©èƒ½åŠ›ä¸ç¨³å®š")
                        quality_score -= 12
        
        # ç”Ÿæˆä¸“ä¸šåˆ†ææŠ¥å‘Š
        analysis_content = f"""
ã€è´¢æŠ¥è´¨é‡è¯„ä¼°æŠ¥å‘Šã€‘
è´¨é‡è¯„åˆ†: {quality_score}/100 {'ğŸŸ¢ä¼˜ç§€' if quality_score >= 80 else 'ğŸŸ¡ä¸€èˆ¬' if quality_score >= 60 else 'ğŸ”´è­¦å‘Š'}

ã€å…³é”®è´¢åŠ¡æŒ‡æ ‡åˆ†æã€‘
æœ€æ–°å­£åº¦è¥ä¸šæ”¶å…¥: {max(revenue_data.values())/100000000:.1f}äº¿å…ƒ
æœ€æ–°å­£åº¦å‡€åˆ©æ¶¦: {max(profit_data.values())/100000000:.1f}äº¿å…ƒ  
æœ€æ–°å­£åº¦ç°é‡‘æµ: {max(cash_flow_data.values())/100000000:.1f}äº¿å…ƒ

ã€è´¢æŠ¥å¼‚å¸¸è¯†åˆ«ã€‘
{'å‘ç°ä»¥ä¸‹å¼‚å¸¸ä¿¡å·ï¼š' if red_flags else 'âœ… æœªå‘ç°æ˜æ˜¾è´¢åŠ¡å¼‚å¸¸'}
{chr(10).join(red_flags) if red_flags else 'è´¢åŠ¡æ•°æ®æ•´ä½“è¡¨ç°æ­£å¸¸ï¼Œå„é¡¹æŒ‡æ ‡åŒ¹é…åº¦è¾ƒå¥½ã€‚'}

ã€ä¸“ä¸šå»ºè®®ã€‘
{'å»ºè®®é‡ç‚¹å…³æ³¨è´¢åŠ¡æ•°æ®çœŸå®æ€§ï¼Œè°¨æ…æŠ•èµ„' if quality_score < 60 else 'è´¢åŠ¡è´¨é‡å°šå¯ï¼Œä½†éœ€æŒç»­è·Ÿè¸ªå…³é”®æŒ‡æ ‡å˜åŒ–' if quality_score < 80 else 'è´¢åŠ¡æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä½œä¸ºæŠ•èµ„å‚è€ƒ'}
        """
        
        result = {
            "expert_type": "financial_statement_analyst",
            "title": f"è´¢æŠ¥åˆ†æä¸“å®¶æŠ¥å‘Š - {stock_code}",
            "content": analysis_content.strip(),
            "quality_score": quality_score,
            "red_flags": red_flags,
            "summary": f"è´¢åŠ¡è´¨é‡å¾—åˆ†{quality_score}åˆ†ï¼Œ{'å‘ç°{len(red_flags)}ä¸ªå¼‚å¸¸' if red_flags else 'è´¢åŠ¡æ•°æ®æ­£å¸¸'}",
            "generated_at": datetime.now().isoformat()
        }
        
        # ç¼“å­˜ç»“æœ
        daily_ai_cache[cache_key] = result
        logger.info(f"ğŸ’¼ è´¢æŠ¥ä¸“å®¶åˆ†æå®Œæˆ: {stock_code} - è´¨é‡å¾—åˆ†{quality_score}")
        return result
        
    except Exception as e:
        logger.error(f"è´¢æŠ¥åˆ†æä¸“å®¶å¼‚å¸¸: {e}")
        return {
            "expert_type": "financial_statement_analyst",
            "title": f"è´¢æŠ¥åˆ†æä¸“å®¶æŠ¥å‘Š - {stock_code}",
            "content": "è´¢æŠ¥æ•°æ®åˆ†æå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•",
            "quality_score": 50,
            "red_flags": [],
            "summary": "åˆ†æå¼‚å¸¸",
            "generated_at": datetime.now().isoformat()
        }

async def market_maker_expert(stock_code: str, technical_data: dict, sentiment_data: dict) -> dict:
    """åº„å®¶åˆ†æä¸“å®¶ - ä¸»åŠ›èµ„é‡‘è¡Œä¸ºåˆ†æ"""
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = get_cache_key(stock_code, "market_maker_expert")
    if is_cache_valid(cache_key):
        logger.info(f"ğŸ”„ ä½¿ç”¨åº„å®¶ä¸“å®¶ç¼“å­˜: {stock_code}")
        return daily_ai_cache[cache_key]
    
    try:
        # è·å–æŠ€æœ¯æŒ‡æ ‡
        volume = technical_data.get("volume", 0)
        turnover_rate = technical_data.get("turnover_rate", 0)
        volume_ratio = technical_data.get("volume_ratio", 1)
        price_change_pct = technical_data.get("price_change_pct", 0)
        market_mood = technical_data.get("market_mood", {})
        
        # åº„å®¶è¡Œä¸ºæ£€æµ‹
        banker_signals = []
        manipulation_score = 0
        
        # 1. å¼‚å¸¸æˆäº¤é‡åˆ†æ
        if volume_ratio > 3:
            banker_signals.append(f"ğŸš¨ é‡æ¯”{volume_ratio:.1f}å€ï¼Œæˆäº¤é‡æš´å¢ï¼Œç–‘ä¼¼ä¸»åŠ›å¤§ä¸¾å»ºä»“æˆ–å‡ºè´§")
            manipulation_score += 25
        elif volume_ratio > 2:
            banker_signals.append(f"âš ï¸ é‡æ¯”{volume_ratio:.1f}å€ï¼Œæˆäº¤é‡æ˜æ˜¾æ”¾å¤§ï¼Œä¸»åŠ›å¯èƒ½æœ‰åŠ¨ä½œ")
            manipulation_score += 15
        elif volume_ratio < 0.5:
            banker_signals.append(f"ğŸ“‰ é‡æ¯”{volume_ratio:.1f}å€ï¼Œæˆäº¤èç¼©ï¼Œä¸»åŠ›è§‚æœ›æˆ–æ§ç›˜ä¸­")
            manipulation_score += 10
        
        # 2. å¤–ç›˜å†…ç›˜åˆ†æ
        outer_disk = market_mood.get("å¤–ç›˜", 0)
        inner_disk = market_mood.get("å†…ç›˜", 0)
        if outer_disk > 0 and inner_disk > 0:
            total_trade = outer_disk + inner_disk
            outer_ratio = outer_disk / total_trade
            
            if outer_ratio > 0.7:
                banker_signals.append(f"ğŸŸ¢ å¤–ç›˜å æ¯”{outer_ratio*100:.1f}%ï¼Œä¸»åŠ¨ä¹°ç›˜å¼ºåŠ²ï¼Œä¸»åŠ›å¸ç­¹æ˜æ˜¾")
                manipulation_score += 20
            elif outer_ratio < 0.3:
                banker_signals.append(f"ğŸ”´ å¤–ç›˜å æ¯”{outer_ratio*100:.1f}%ï¼Œä¸»åŠ¨å–ç›˜å ä¼˜ï¼Œä¸»åŠ›å¯èƒ½å‡ºè´§")
                manipulation_score += 20
            elif 0.45 <= outer_ratio <= 0.55:
                banker_signals.append(f"âš–ï¸ å¤–ç›˜å æ¯”{outer_ratio*100:.1f}%ï¼Œå¤šç©ºå¹³è¡¡ï¼Œä¸»åŠ›æ§ç›˜ç¨³å®š")
                manipulation_score += 5
        
        # 3. æ¶¨è·Œå¹…ä¸æˆäº¤é‡åŒ¹é…åº¦
        if abs(price_change_pct) > 5 and volume_ratio < 1.5:
            banker_signals.append(f"ğŸ¯ è‚¡ä»·{'+' if price_change_pct > 0 else ''}{price_change_pct:.1f}%å¤§å¹…å˜åŠ¨ä½†æˆäº¤é‡æœªæ”¾å¤§ï¼Œç–‘ä¼¼æ§ç›˜æ‹‰å‡/æ‰“å‹")
            manipulation_score += 30
        elif abs(price_change_pct) < 2 and volume_ratio > 2.5:
            banker_signals.append(f"ğŸ”„ è‚¡ä»·æ³¢åŠ¨å°({price_change_pct:+.1f}%)ä½†æˆäº¤é‡å¤§å¢ï¼Œç–‘ä¼¼ä¸»åŠ›å¯¹å€’æˆ–æ¢åº„")
            manipulation_score += 25
        
        # 4. æ¢æ‰‹ç‡åˆ†æ
        if turnover_rate > 10:
            banker_signals.append(f"ğŸ”¥ æ¢æ‰‹ç‡{turnover_rate:.1f}%ï¼Œèµ„é‡‘éå¸¸æ´»è·ƒï¼Œä¸»åŠ›å¤§å¹…æ“ä½œ")
            manipulation_score += 20
        elif turnover_rate > 5:
            banker_signals.append(f"ğŸ“ˆ æ¢æ‰‹ç‡{turnover_rate:.1f}%ï¼Œèµ„é‡‘æ´»è·ƒåº¦è¾ƒé«˜ï¼Œæœ‰ä¸»åŠ›å‚ä¸")
            manipulation_score += 10
        elif turnover_rate < 1:
            banker_signals.append(f"ğŸ”’ æ¢æ‰‹ç‡{turnover_rate:.1f}%ï¼Œç­¹ç é”å®šåº¦é«˜ï¼Œä¸»åŠ›æ§ç›˜ç¨³å®š")
            manipulation_score += 15
        
        # ç»¼åˆè¯„ä¼°
        if manipulation_score >= 60:
            risk_level = "ğŸš¨ é«˜åº¦ç–‘ä¼¼åº„å®¶æ“æ§"
            advice = "å»ºè®®è°¨æ…è·Ÿé£ï¼Œæ³¨æ„ä¸»åŠ›å‡ºè´§é£é™©"
        elif manipulation_score >= 30:
            risk_level = "âš ï¸ å­˜åœ¨ä¸»åŠ›æ“ä½œè¿¹è±¡"
            advice = "å¯é€‚é‡å‚ä¸ï¼Œä½†éœ€å¯†åˆ‡å…³æ³¨èµ„é‡‘åŠ¨å‘"
        else:
            risk_level = "âœ… æš‚æœªå‘ç°æ˜æ˜¾æ“æ§"
            advice = "å¸‚åœºäº¤æ˜“ç›¸å¯¹è‡ªç„¶ï¼Œå¯æ­£å¸¸æŠ•èµ„å†³ç­–"
        
        analysis_content = f"""
ã€åº„å®¶è¡Œä¸ºåˆ†ææŠ¥å‘Šã€‘
æ“æ§å«Œç–‘åº¦: {manipulation_score}/100 {risk_level}

ã€å…³é”®èµ„é‡‘æŒ‡æ ‡ã€‘
æˆäº¤é‡: {volume:,.0f}æ‰‹ (é‡æ¯”{volume_ratio:.1f})
æ¢æ‰‹ç‡: {turnover_rate:.1f}%
å¤–ç›˜å æ¯”: {outer_ratio*100:.1f}% (å¤–:{outer_disk:,.0f} å†…:{inner_disk:,.0f})

ã€ä¸»åŠ›è¡Œä¸ºè¯†åˆ«ã€‘
{'æ£€æµ‹åˆ°ä»¥ä¸‹å¼‚å¸¸ä¿¡å·ï¼š' if banker_signals else 'âœ… æœªå‘ç°æ˜æ˜¾åº„å®¶æ“æ§ç—•è¿¹'}
{chr(10).join(banker_signals) if banker_signals else 'æˆäº¤æ•°æ®æ˜¾ç¤ºå¸‚åœºäº¤æ˜“è¡Œä¸ºç›¸å¯¹è‡ªç„¶ï¼Œæ— æ˜æ˜¾äººä¸ºæ“æ§è¿¹è±¡ã€‚'}

ã€æŠ•èµ„å»ºè®®ã€‘
{advice}
        """
        
        result = {
            "expert_type": "market_maker_analyst",
            "title": f"åº„å®¶åˆ†æä¸“å®¶æŠ¥å‘Š - {stock_code}",
            "content": analysis_content.strip(),
            "manipulation_score": manipulation_score,
            "banker_signals": banker_signals,
            "risk_level": risk_level,
            "summary": f"æ“æ§å«Œç–‘{manipulation_score}åˆ†ï¼Œ{risk_level}",
            "generated_at": datetime.now().isoformat()
        }
        
        # ç¼“å­˜ç»“æœ
        daily_ai_cache[cache_key] = result
        logger.info(f"ğŸ¯ åº„å®¶ä¸“å®¶åˆ†æå®Œæˆ: {stock_code} - å«Œç–‘åº¦{manipulation_score}")
        return result
        
    except Exception as e:
        logger.error(f"åº„å®¶åˆ†æä¸“å®¶å¼‚å¸¸: {e}")
        return {
            "expert_type": "market_maker_analyst", 
            "title": f"åº„å®¶åˆ†æä¸“å®¶æŠ¥å‘Š - {stock_code}",
            "content": "åº„å®¶è¡Œä¸ºåˆ†æå¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•",
            "manipulation_score": 0,
            "banker_signals": [],
            "risk_level": "åˆ†æå¼‚å¸¸",
            "summary": "åˆ†æå¼‚å¸¸",
            "generated_at": datetime.now().isoformat()
        }

# AIåˆ†ææ¥å£
@app.post("/api/ai/analyze")
async def ai_analyze_stock(stock_code: str, analysis_style: str = "professional"):
    """AIåˆ†æè‚¡ç¥¨æ•°æ® (åŸºäºçœŸå®æ•°æ®) - å¸¦æ¯æ—¥ç¼“å­˜"""
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = get_cache_key(stock_code, f"ai_{analysis_style}")
    if is_cache_valid(cache_key):
        logger.info(f"ğŸ”„ ä½¿ç”¨AIåˆ†æç¼“å­˜: {stock_code} - {analysis_style}")
        cached_result = daily_ai_cache[cache_key]
        
        # æ›´æ–°å®æ—¶ä»·æ ¼æ•°æ®ä½†ä¿ç•™AIåˆ†æå†…å®¹
        try:
            fresh_stock_data = await fetch_real_stock_data(stock_code)
            fundamental = fresh_stock_data.get("fundamental", {})
            cached_result["current_price"] = fundamental.get("current_price", 0)
            cached_result["price_change"] = fresh_stock_data.get("technical", {}).get("price_change", 0)
            cached_result["price_change_pct"] = fresh_stock_data.get("technical", {}).get("price_change_pct", 0)
            cached_result["last_updated"] = datetime.now().isoformat()
        except:
            pass  # å¦‚æœè·å–å®æ—¶æ•°æ®å¤±è´¥ï¼Œä»è¿”å›ç¼“å­˜çš„ç»“æœ
            
        return cached_result
    
    try:
        # è·å–çœŸå®è‚¡ç¥¨æ•°æ®ç”¨äºåˆ†æ
        stock_data = await fetch_real_stock_data(stock_code)
        fundamental = stock_data.get("fundamental", {})
        technical = stock_data.get("technical", {})
        financial = stock_data.get("financial", {})
        
        stock_name = fundamental.get("stock_name", stock_code)
        current_price = fundamental.get("current_price", 0)
        pe_ratio = fundamental.get("pe_ratio", 0)
        industry = fundamental.get("industry", "æœªçŸ¥")
        market_cap = fundamental.get("market_cap", 0) / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
        
        # åŸºäºçœŸå®æ•°æ®ç”Ÿæˆåˆ†æå†…å®¹
        style_templates = {
            "professional": {
                "title": f"{stock_name}({stock_code}) èµ„æ·±åˆ†æå¸ˆæ·±åº¦æŠ¥å‘Š",
                "content": f"ä½œä¸ºæ‹¥æœ‰15å¹´Aè‚¡ç ”ç©¶ç»éªŒçš„èµ„æ·±åˆ†æå¸ˆï¼Œæˆ‘å¯¹{stock_name}({stock_code})è¿›è¡Œäº†å…¨é¢åˆ†æã€‚è¯¥è‚¡å±äº{industry}è¡Œä¸šï¼Œå½“å‰è‚¡ä»·{current_price}å…ƒï¼Œæ€»å¸‚å€¼{market_cap:.0f}äº¿å…ƒï¼Œå¸‚ç›ˆç‡{pe_ratio}å€ã€‚ä»åŸºæœ¬é¢çœ‹ï¼Œå…¬å¸è´¢åŠ¡æŒ‡æ ‡è¡¨ç°{get_performance_assessment(pe_ratio)}ï¼Œä¼°å€¼æ°´å¹³{get_valuation_assessment(pe_ratio)}ã€‚æŠ€æœ¯é¢æ˜¾ç¤º{technical.get('trend', 'è¶‹åŠ¿å¾…è§‚å¯Ÿ')}ã€‚ç»¼åˆåˆ†æï¼Œå»ºè®®æŠ•èµ„è€…ç†æ€§çœ‹å¾…ï¼Œæ³¨æ„é£é™©æ§åˆ¶ã€‚",
                "summary": f"å¸‚å€¼{market_cap:.0f}äº¿ï¼ŒPE{pe_ratio}å€ï¼Œ{get_investment_suggestion(pe_ratio, market_cap)}",
                "tone": "ä¸“ä¸šã€æ·±åº¦ã€å®¢è§‚"
            },
            "dark": {
                "title": f"{stock_name}({stock_code}) æš—é»‘è¯„è®ºå‘˜ç‹¬ç«‹è§‚ç‚¹", 
                "content": f"è€é“ä»¬ï¼Œä»Šå¤©æ‰’ä¸€æ‰’{stock_name}({stock_code})ã€‚å½“å‰ä»·æ ¼{current_price}å…ƒï¼Œå¸‚å€¼{market_cap:.0f}äº¿ï¼ŒPEé«˜è¾¾{pe_ratio}å€{'ï¼Œä¼°å€¼æ˜æ˜¾åé«˜' if pe_ratio > 30 else 'ï¼Œä¼°å€¼è¿˜ç®—åˆç†'}ã€‚{industry}è¿™ä¸ªè¡Œä¸š{'ç«äº‰æ¿€çƒˆï¼Œè¦å°å¿ƒ' if industry in ['è½¯ä»¶æœåŠ¡', 'äº’è”ç½‘', 'ç”µå­ä¿¡æ¯'] else 'ç›¸å¯¹ç¨³å®š'}ã€‚{'å¤§ç›˜è‚¡ç›¸å¯¹å®‰å…¨äº›' if market_cap > 1000 else 'ä¸­å°ç›˜é£é™©è¾ƒé«˜'}ï¼Œä½†ä¹Ÿè¦é˜²æ­¢æœºæ„å‰²éŸ­èœã€‚è®°ä½ï¼šè‚¡å¸‚æœ‰é£é™©ï¼Œæ´»ç€æœ€é‡è¦ï¼",
                "summary": f"ä»·æ ¼{current_price}å…ƒï¼ŒPE{pe_ratio}å€ï¼Œ{get_risk_warning(pe_ratio, market_cap)}",
                "tone": "çŠ€åˆ©ã€ç‹¬ç«‹ã€é£é™©æç¤º"
            },
            "optimistic": {
                "title": f"{stock_name}({stock_code}) æŠ•èµ„æœºä¼šæ·±åº¦æŒ–æ˜",
                "content": f"{stock_name}({stock_code})å±•ç°å‡ºä¸ä¿—çš„æŠ•èµ„ä»·å€¼ï¼å½“å‰ä»·æ ¼{current_price}å…ƒï¼Œå¤„äº{industry}è¿™ä¸ª{'é«˜æˆé•¿' if industry in ['æ–°èƒ½æº', 'ç§‘æŠ€', 'åŒ»è¯'] else 'ç¨³å¥'}è¡Œä¸šã€‚å¸‚å€¼{market_cap:.0f}äº¿{'ï¼Œä»æœ‰æˆé•¿ç©ºé—´' if market_cap < 500 else 'ï¼Œè¡Œä¸šåœ°ä½ç¨³å›º'}ï¼ŒPE{pe_ratio}å€{'åˆç†ä¼°å€¼' if pe_ratio < 25 else 'åæ˜ å¸‚åœºé¢„æœŸ'}ã€‚æŠ€æœ¯é¢å‘ˆç°{technical.get('trend', 'ç§¯æä¿¡å·')}ï¼Œæ˜¯å¸ƒå±€çš„å¥½æ—¶æœºï¼",
                "summary": f"ä»·æ ¼{current_price}å…ƒï¼Œ{industry}æ¿å—ï¼ŒæŠ•èµ„æœºä¼š{get_opportunity_level(pe_ratio, market_cap)}",
                "tone": "ç§¯æã€ä¹è§‚"
            },
            "conservative": {
                "title": f"{stock_name}({stock_code}) ç¨³å¥æŠ•èµ„è¯„ä¼°",
                "content": f"ä»ç¨³å¥æŠ•èµ„è§’åº¦è¯„ä¼°{stock_name}({stock_code})ï¼šè‚¡ä»·{current_price}å…ƒï¼Œå¸‚å€¼{market_cap:.0f}äº¿ï¼ŒPE{pe_ratio}å€ã€‚ä½œä¸º{industry}è¡Œä¸šçš„{'é¾™å¤´ä¼ä¸š' if market_cap > 1000 else 'æˆé•¿å‹ä¼ä¸š'}ï¼Œ{'åŸºæœ¬é¢ç›¸å¯¹ç¨³å¥' if pe_ratio < 30 else 'éœ€å…³æ³¨ä¼°å€¼é£é™©'}ã€‚å»ºè®®{'é€‚é‡é…ç½®' if pe_ratio < 25 else 'è°¨æ…è§‚æœ›'}ï¼Œé‡‡ç”¨åˆ†æ‰¹å»ºä»“ç­–ç•¥ï¼Œè®¾ç½®åˆç†æ­¢æŸä½ã€‚",
                "summary": f"å¸‚å€¼{market_cap:.0f}äº¿ï¼ŒPE{pe_ratio}å€ï¼Œ{get_conservative_advice(pe_ratio, market_cap)}",
                "tone": "ç¨³é‡ã€ä¿å®ˆ"
            }
        }
        
        template = style_templates.get(analysis_style, style_templates["professional"])
        
        analysis_result = {
            "agent_id": f"real_agent_{analysis_style}",
            "style": analysis_style,
            "title": template["title"],
            "content": template["content"],
            "summary": template["summary"],
            "recommendations": get_recommendations(pe_ratio, market_cap, analysis_style),
            "confidence_score": 0.8,
            "risk_assessment": get_risk_level(pe_ratio, market_cap),
            "generated_at": datetime.now().isoformat(),
            "processing_time": 0.5,
            "data_quality": "real_data",
            "current_price": current_price,
            "price_change": technical.get("price_change", 0),
            "price_change_pct": technical.get("price_change_pct", 0),
            "last_updated": datetime.now().isoformat()
        }
        
        # ç¼“å­˜åˆ†æç»“æœ
        daily_ai_cache[cache_key] = analysis_result
        
        logger.info(f"âœ… å®ŒæˆAIåˆ†æ: {stock_code} - {analysis_style}é£æ ¼ - åŸºäºçœŸå®æ•°æ® - å·²ç¼“å­˜")
        return analysis_result
        
    except Exception as e:
        logger.error(f"AIåˆ†æå¤±è´¥: {stock_code} - {e}")
        raise HTTPException(status_code=500, detail=f"AIåˆ†æå¤±è´¥: {str(e)}")

# ä¸“ä¸šåˆ†æå¸ˆæ¥å£
@app.post("/api/experts/financial")
async def financial_expert_analysis(stock_code: str):
    """è´¢æŠ¥åˆ†æä¸“å®¶æ¥å£"""
    try:
        # è·å–è‚¡ç¥¨æ•°æ®
        stock_data = await fetch_real_stock_data(stock_code)
        financial_data = stock_data.get("financial", {})
        
        # è°ƒç”¨è´¢æŠ¥åˆ†æä¸“å®¶
        result = await financial_statement_expert(stock_code, financial_data)
        
        logger.info(f"ğŸ’¼ è´¢æŠ¥ä¸“å®¶åˆ†æè¯·æ±‚: {stock_code}")
        return result
        
    except Exception as e:
        logger.error(f"è´¢æŠ¥ä¸“å®¶åˆ†æå¤±è´¥: {stock_code} - {e}")
        raise HTTPException(status_code=500, detail=f"è´¢æŠ¥ä¸“å®¶åˆ†æå¤±è´¥: {str(e)}")

@app.post("/api/experts/market-maker")
async def market_maker_expert_analysis(stock_code: str):
    """åº„å®¶åˆ†æä¸“å®¶æ¥å£"""
    try:
        # è·å–è‚¡ç¥¨æ•°æ®
        stock_data = await fetch_real_stock_data(stock_code)
        technical_data = stock_data.get("technical", {})
        sentiment_data = stock_data.get("sentiment", {})
        
        # è°ƒç”¨åº„å®¶åˆ†æä¸“å®¶
        result = await market_maker_expert(stock_code, technical_data, sentiment_data)
        
        logger.info(f"ğŸ¯ åº„å®¶ä¸“å®¶åˆ†æè¯·æ±‚: {stock_code}")
        return result
        
    except Exception as e:
        logger.error(f"åº„å®¶ä¸“å®¶åˆ†æå¤±è´¥: {stock_code} - {e}")
        raise HTTPException(status_code=500, detail=f"åº„å®¶ä¸“å®¶åˆ†æå¤±è´¥: {str(e)}")

@app.post("/api/experts/comprehensive")
async def comprehensive_expert_analysis(stock_code: str):
    """ç»¼åˆä¸“å®¶åˆ†ææ¥å£ - åŒ…å«è´¢æŠ¥å’Œåº„å®¶åŒé‡åˆ†æ"""
    try:
        # è·å–è‚¡ç¥¨æ•°æ®
        stock_data = await fetch_real_stock_data(stock_code)
        fundamental = stock_data.get("fundamental", {})
        financial_data = stock_data.get("financial", {})
        technical_data = stock_data.get("technical", {})
        sentiment_data = stock_data.get("sentiment", {})
        
        # å¹¶è¡Œè°ƒç”¨ä¸¤ä¸ªä¸“å®¶
        financial_analysis, market_maker_analysis = await asyncio.gather(
            financial_statement_expert(stock_code, financial_data),
            market_maker_expert(stock_code, technical_data, sentiment_data)
        )
        
        # ç»¼åˆè¯„ä¼°
        stock_name = fundamental.get("stock_name", stock_code)
        current_price = fundamental.get("current_price", 0)
        
        # è®¡ç®—ç»¼åˆé£é™©è¯„åˆ†
        financial_score = financial_analysis.get("quality_score", 50)
        manipulation_score = market_maker_analysis.get("manipulation_score", 0)
        
        # ç»¼åˆé£é™©è¯„çº§ (0-100ï¼Œè¶Šä½è¶Šå®‰å…¨)
        comprehensive_risk = ((100 - financial_score) * 0.6 + manipulation_score * 0.4)
        
        if comprehensive_risk <= 20:
            risk_rating = "ğŸŸ¢ ä½é£é™©"
            investment_advice = "è´¢åŠ¡è´¨é‡è‰¯å¥½ï¼Œå¸‚åœºè¡Œä¸ºè‡ªç„¶ï¼Œå¯è€ƒè™‘æŠ•èµ„"
        elif comprehensive_risk <= 40:
            risk_rating = "ğŸŸ¡ ä¸­ç­‰é£é™©"
            investment_advice = "è´¢åŠ¡æˆ–äº¤æ˜“å­˜åœ¨ä¸€å®šé—®é¢˜ï¼Œéœ€è°¨æ…åˆ†æ"
        elif comprehensive_risk <= 60:
            risk_rating = "ğŸŸ  è¾ƒé«˜é£é™©"  
            investment_advice = "è´¢åŠ¡è´¨é‡æˆ–å¸‚åœºæ“æ§é£é™©è¾ƒé«˜ï¼Œä¸å»ºè®®æŠ•èµ„"
        else:
            risk_rating = "ğŸ”´ é«˜é£é™©"
            investment_advice = "å­˜åœ¨ä¸¥é‡è´¢åŠ¡é—®é¢˜æˆ–åº„å®¶æ“æ§å«Œç–‘ï¼Œå¼ºçƒˆä¸å»ºè®®æŠ•èµ„"
        
        result = {
            "stock_code": stock_code,
            "stock_name": stock_name,
            "current_price": current_price,
            "comprehensive_risk_score": round(comprehensive_risk, 1),
            "risk_rating": risk_rating,
            "investment_advice": investment_advice,
            "financial_analysis": financial_analysis,
            "market_maker_analysis": market_maker_analysis,
            "analysis_summary": {
                "financial_quality": f"{financial_score}/100åˆ†",
                "manipulation_risk": f"{manipulation_score}/100åˆ†",
                "overall_assessment": f"{risk_rating} - {investment_advice}"
            },
            "generated_at": datetime.now().isoformat()
        }
        
        logger.info(f"ğŸ” ç»¼åˆä¸“å®¶åˆ†æå®Œæˆ: {stock_code} - é£é™©è¯„åˆ†{comprehensive_risk:.1f}")
        return result
        
    except Exception as e:
        logger.error(f"ç»¼åˆä¸“å®¶åˆ†æå¤±è´¥: {stock_code} - {e}")
        raise HTTPException(status_code=500, detail=f"ç»¼åˆä¸“å®¶åˆ†æå¤±è´¥: {str(e)}")

# ç¼“å­˜ç®¡ç†æ¥å£
@app.get("/api/cache/status")
async def get_cache_status():
    """è·å–ç¼“å­˜çŠ¶æ€"""
    today = datetime.now().strftime("%Y-%m-%d")
    
    # ç»Ÿè®¡ä»Šæ—¥ç¼“å­˜
    today_cache = {k: v for k, v in daily_ai_cache.items() if today in k}
    
    cache_stats = {
        "total_cached_analyses": len(daily_ai_cache),
        "today_cached_analyses": len(today_cache),
        "cache_date": today,
        "cache_types": {}
    }
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    for key in today_cache.keys():
        analysis_type = key.split('_')[1] if len(key.split('_')) >= 2 else 'unknown'
        cache_stats["cache_types"][analysis_type] = cache_stats["cache_types"].get(analysis_type, 0) + 1
    
    return cache_stats

@app.delete("/api/cache/clear")
async def clear_cache():
    """æ¸…ç†ç¼“å­˜"""
    global daily_ai_cache
    old_count = len(daily_ai_cache)
    daily_ai_cache.clear()
    
    logger.info(f"ğŸ—‘ï¸ ç¼“å­˜å·²æ¸…ç†ï¼Œæ¸…ç†äº†{old_count}ä¸ªç¼“å­˜é¡¹")
    return {
        "message": "ç¼“å­˜å·²æ¸…ç†",
        "cleared_count": old_count,
        "cleared_at": datetime.now().isoformat()
    }

# æ–‡ä»¶ä¸Šä¼ æ¥å£
@app.post("/api/upload/logo")
async def upload_logo(file: UploadFile = File(...)):
    """ä¸Šä¼ åº”ç”¨logo"""
    try:
        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒå›¾ç‰‡æ ¼å¼æ–‡ä»¶")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å° (æœ€å¤§5MB)
        file_size = 0
        file_content = await file.read()
        file_size = len(file_content)
        
        if file_size > 5 * 1024 * 1024:  # 5MB
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡5MB")
        
        # ç¡®ä¿assetsç›®å½•å­˜åœ¨
        assets_dir = "frontend/assets"
        os.makedirs(assets_dir, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        file_extension = os.path.splitext(file.filename)[1].lower()
        if not file_extension in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")
        
        filename = f"logo{file_extension}"
        file_path = os.path.join(assets_dir, filename)
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            buffer.write(file_content)
        
        # è¿”å›æ–‡ä»¶è®¿é—®URL
        file_url = f"/assets/{filename}"
        
        logger.info(f"ğŸ“ Logoä¸Šä¼ æˆåŠŸ: {filename} ({file_size} bytes)")
        
        return {
            "message": "Logoä¸Šä¼ æˆåŠŸ",
            "filename": filename,
            "file_url": file_url,
            "file_size": file_size,
            "uploaded_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Logoä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")

# é¾™è™æ¦œæ•°æ®API
@app.get("/api/stocks/{stock_code}/longhubang")
async def get_longhubang_data(stock_code: str):
    """è·å–è‚¡ç¥¨é¾™è™æ¦œæ•°æ®"""
    try:
        # æ¨¡æ‹Ÿé¾™è™æ¦œæ•°æ®
        longhubang_data = {
            "stock_code": stock_code,
            "date": "2025-09-05",
            "reason": "æ—¥æ¶¨å¹…åç¦»å€¼è¾¾7%çš„è¯åˆ¸",
            "buy_top5": [
                {
                    "rank": 1,
                    "seat_name": "åæ³°è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ·±åœ³ç›Šç”°è·¯è£è¶…å•†åŠ¡ä¸­å¿ƒè¥ä¸šéƒ¨",
                    "buy_amount": 45678900,
                    "sell_amount": 1234500,
                    "net_amount": 44444400,
                    "type": "æœºæ„ä¸“ç”¨"
                },
                {
                    "rank": 2,
                    "seat_name": "ä¸­ä¿¡å»ºæŠ•è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸åŒ—äº¬ä¸œç›´é—¨å—å¤§è¡—è¥ä¸šéƒ¨",
                    "buy_amount": 38765400,
                    "sell_amount": 2345600,
                    "net_amount": 36419800,
                    "type": "æ¸¸èµ„"
                },
                {
                    "rank": 3,
                    "seat_name": "å›½æ³°å›å®‰è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·æ±Ÿè‹è·¯è¥ä¸šéƒ¨",
                    "buy_amount": 32156700,
                    "sell_amount": 5678900,
                    "net_amount": 26477800,
                    "type": "æœºæ„ä¸“ç”¨"
                },
                {
                    "rank": 4,
                    "seat_name": "æ‹›å•†è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ·±åœ³è›‡å£å·¥ä¸šä¸€è·¯è¥ä¸šéƒ¨",
                    "buy_amount": 28934500,
                    "sell_amount": 3456780,
                    "net_amount": 25477720,
                    "type": "æ¸¸èµ„"
                },
                {
                    "rank": 5,
                    "seat_name": "å¹¿å‘è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸å¹¿å·å¤©æ²³åŒ—è·¯è¥ä¸šéƒ¨",
                    "buy_amount": 24567800,
                    "sell_amount": 1987600,
                    "net_amount": 22580200,
                    "type": "æ¸¸èµ„"
                }
            ],
            "sell_top5": [
                {
                    "rank": 1,
                    "seat_name": "ä¸œæ–¹è´¢å¯Œè¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ‹‰è¨å›¢ç»“è·¯ç¬¬äºŒè¥ä¸šéƒ¨",
                    "buy_amount": 2345600,
                    "sell_amount": 53467800,
                    "net_amount": -51122200,
                    "type": "æ¸¸èµ„"
                },
                {
                    "rank": 2,
                    "seat_name": "é“¶æ²³è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸åŒ—äº¬ä¸­å…³æ‘å¤§è¡—è¥ä¸šéƒ¨",
                    "buy_amount": 1234500,
                    "sell_amount": 41234500,
                    "net_amount": -40000000,
                    "type": "æ¸¸èµ„"
                },
                {
                    "rank": 3,
                    "seat_name": "ä¸­ä¿¡è¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸ä¸Šæµ·æ·®æµ·ä¸­è·¯è¥ä¸šéƒ¨",
                    "buy_amount": 3456700,
                    "sell_amount": 38765400,
                    "net_amount": -35308700,
                    "type": "æœºæ„ä¸“ç”¨"
                },
                {
                    "rank": 4,
                    "seat_name": "æµ·é€šè¯åˆ¸è‚¡ä»½æœ‰é™å…¬å¸æ·±åœ³çº¢è”è·¯è¥ä¸šéƒ¨",
                    "buy_amount": 2987600,
                    "sell_amount": 32156700,
                    "net_amount": -29169100,
                    "type": "æ¸¸èµ„"
                },
                {
                    "rank": 5,
                    "seat_name": "ç”³ä¸‡å®æºè¯åˆ¸æœ‰é™å…¬å¸ä¸Šæµ·ä¸œå·è·¯è¥ä¸šéƒ¨",
                    "buy_amount": 4567800,
                    "sell_amount": 28934500,
                    "net_amount": -24366700,
                    "type": "æ¸¸èµ„"
                }
            ],
            "total_buy": 170102500,
            "total_sell": 194569500,
            "net_amount": -24467000,
            "turnover": 876543200
        }
        
        logger.info(f"ğŸ² è·å–é¾™è™æ¦œæ•°æ®: {stock_code}")
        return longhubang_data
        
    except Exception as e:
        logger.error(f"è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {e}")
        return {
            "error": f"è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {str(e)}",
            "stock_code": stock_code
        }

# å…¬å¸å…¬å‘ŠAPI
@app.get("/api/stocks/{stock_code}/announcements")
async def get_announcements(stock_code: str, limit: int = 10):
    """è·å–å…¬å¸å…¬å‘Šæ•°æ®"""
    try:
        # æ¨¡æ‹Ÿå…¬å¸å…¬å‘Šæ•°æ®
        announcements = [
            {
                "id": "2025090501",
                "title": "å…³äºå¬å¼€2025å¹´ç¬¬ä¸‰æ¬¡ä¸´æ—¶è‚¡ä¸œå¤§ä¼šçš„é€šçŸ¥",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-09-05",
                "importance": "é‡è¦",
                "summary": "å…¬å¸æ‹Ÿå¬å¼€2025å¹´ç¬¬ä¸‰æ¬¡ä¸´æ—¶è‚¡ä¸œå¤§ä¼šï¼Œå®¡è®®é‡å¤§èµ„äº§é‡ç»„ç›¸å…³è®®æ¡ˆ",
                "keywords": ["è‚¡ä¸œå¤§ä¼š", "é‡å¤§èµ„äº§é‡ç»„"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025090501.pdf"
            },
            {
                "id": "2025090301",
                "title": "å…³äºé‡å¤§èµ„äº§é‡ç»„è¿›å±•çš„å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-09-03",
                "importance": "é‡è¦",
                "summary": "å…¬å¸é‡å¤§èµ„äº§é‡ç»„é¡¹ç›®å·²å®Œæˆå°½èŒè°ƒæŸ¥ï¼Œæ­£åœ¨è¿›è¡Œèµ„äº§è¯„ä¼°å·¥ä½œ",
                "keywords": ["é‡å¤§èµ„äº§é‡ç»„", "å°½èŒè°ƒæŸ¥", "èµ„äº§è¯„ä¼°"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025090301.pdf"
            },
            {
                "id": "2025090201",
                "title": "2025å¹´åŠå¹´åº¦ä¸šç»©å¿«æŠ¥",
                "type": "å®šæœŸæŠ¥å‘Š",
                "date": "2025-09-02",
                "importance": "é‡è¦",
                "summary": "2025å¹´ä¸ŠåŠå¹´å®ç°è¥ä¸šæ”¶å…¥15.6äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿12.3%ï¼›å‡€åˆ©æ¶¦2.1äº¿å…ƒï¼ŒåŒæ¯”å¢é•¿8.7%",
                "keywords": ["åŠå¹´æŠ¥", "ä¸šç»©å¿«æŠ¥", "è¥ä¸šæ”¶å…¥"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025090201.pdf"
            },
            {
                "id": "2025083101",
                "title": "å…³äºé«˜çº§ç®¡ç†äººå‘˜è¾èŒçš„å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-08-31",
                "importance": "ä¸€èˆ¬",
                "summary": "å…¬å¸å‰¯æ€»ç»ç†å¼ XXå› ä¸ªäººåŸå› è¾èŒï¼Œè¾èŒåä¸åœ¨å…¬å¸æ‹…ä»»ä»»ä½•èŒåŠ¡",
                "keywords": ["äººäº‹å˜åŠ¨", "é«˜ç®¡è¾èŒ"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025083101.pdf"
            },
            {
                "id": "2025083001",
                "title": "å…³äºè·å¾—æ”¿åºœè¡¥åŠ©çš„å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-08-30",
                "importance": "ä¸€èˆ¬",
                "summary": "å…¬å¸æ”¶åˆ°æ”¿åºœç§‘æŠ€åˆ›æ–°ä¸“é¡¹è¡¥åŠ©èµ„é‡‘500ä¸‡å…ƒ",
                "keywords": ["æ”¿åºœè¡¥åŠ©", "ç§‘æŠ€åˆ›æ–°"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025083001.pdf"
            },
            {
                "id": "2025082801",
                "title": "å…³äºç­¾ç½²æˆ˜ç•¥åˆä½œåè®®çš„å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-08-28",
                "importance": "é‡è¦",
                "summary": "å…¬å¸ä¸XXXç§‘æŠ€æœ‰é™å…¬å¸ç­¾ç½²æˆ˜ç•¥åˆä½œåè®®ï¼Œå…±åŒå¼€å±•äººå·¥æ™ºèƒ½æŠ€æœ¯ç ”å‘",
                "keywords": ["æˆ˜ç•¥åˆä½œ", "äººå·¥æ™ºèƒ½", "æŠ€æœ¯ç ”å‘"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025082801.pdf"
            },
            {
                "id": "2025082501",
                "title": "å…³äºè‚¡ä¸œå‡æŒè®¡åˆ’çš„é¢„æŠ«éœ²å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-08-25",
                "importance": "é‡è¦",
                "summary": "æŒè‚¡5%ä»¥ä¸Šè‚¡ä¸œæ‹Ÿåœ¨æœªæ¥6ä¸ªæœˆå†…å‡æŒä¸è¶…è¿‡å…¬å¸æ€»è‚¡æœ¬çš„2%",
                "keywords": ["è‚¡ä¸œå‡æŒ", "å‡æŒè®¡åˆ’"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025082501.pdf"
            },
            {
                "id": "2025082201",
                "title": "å…³äºå›è´­å…¬å¸è‚¡ä»½çš„è¿›å±•å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-08-22",
                "importance": "ä¸€èˆ¬",
                "summary": "æˆªè‡³æœ¬å…¬å‘Šæ—¥ï¼Œå…¬å¸å·²ç´¯è®¡å›è´­è‚¡ä»½123.45ä¸‡è‚¡ï¼Œå å…¬å¸æ€»è‚¡æœ¬çš„0.12%",
                "keywords": ["è‚¡ä»½å›è´­", "å›è´­è¿›å±•"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025082201.pdf"
            },
            {
                "id": "2025082001",
                "title": "2025å¹´ç¬¬äºŒå­£åº¦æŠ¥å‘Š",
                "type": "å®šæœŸæŠ¥å‘Š",
                "date": "2025-08-20",
                "importance": "é‡è¦",
                "summary": "å…¬å¸2025å¹´ç¬¬äºŒå­£åº¦å®ç°è¥ä¸šæ”¶å…¥8.2äº¿å…ƒï¼Œå‡€åˆ©æ¶¦1.1äº¿å…ƒ",
                "keywords": ["å­£åº¦æŠ¥å‘Š", "è´¢åŠ¡æ•°æ®"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025082001.pdf"
            },
            {
                "id": "2025081801",
                "title": "å…³äºæŠ•èµ„è®¾ç«‹å­å…¬å¸çš„å…¬å‘Š",
                "type": "ä¸´æ—¶å…¬å‘Š",
                "date": "2025-08-18",
                "importance": "é‡è¦",
                "summary": "å…¬å¸æ‹ŸæŠ•èµ„3000ä¸‡å…ƒè®¾ç«‹å…¨èµ„å­å…¬å¸ï¼Œä¸»è¦ä»äº‹æ–°èƒ½æºæŠ€æœ¯å¼€å‘",
                "keywords": ["æŠ•èµ„", "å­å…¬å¸", "æ–°èƒ½æº"],
                "url": f"http://www.cninfo.com.cn/announcement/{stock_code}_2025081801.pdf"
            }
        ]
        
        # è¿”å›æŒ‡å®šæ•°é‡çš„å…¬å‘Š
        result_announcements = announcements[:limit]
        
        logger.info(f"ğŸ“¢ è·å–å…¬å¸å…¬å‘Šæ•°æ®: {stock_code}, æ•°é‡: {len(result_announcements)}")
        
        return {
            "stock_code": stock_code,
            "total_count": len(announcements),
            "returned_count": len(result_announcements),
            "announcements": result_announcements,
            "last_update": "2025-09-05T10:30:00"
        }
        
    except Exception as e:
        logger.error(f"è·å–å…¬å¸å…¬å‘Šå¤±è´¥: {e}")
        return {
            "error": f"è·å–å…¬å¸å…¬å‘Šå¤±è´¥: {str(e)}",
            "stock_code": stock_code,
            "announcements": []
        }

# æ–‡ç« ç”Ÿæˆå·¥ä½œæµ
@app.post("/api/generate-articles", response_model=TaskResponse)
async def generate_articles(request: ArticleRequest):
    """ç”Ÿæˆè‚¡ç¥¨åˆ†ææ–‡ç« """
    
    task_id = str(uuid.uuid4())
    
    # é»˜è®¤æ–‡ç« é£æ ¼
    if not request.article_styles:
        request.article_styles = ["professional", "optimistic", "conservative"]
    
    # æ¨¡æ‹Ÿå¼‚æ­¥ä»»åŠ¡å¤„ç†
    task_info = {
        "task_id": task_id,
        "stock_code": request.stock_code,
        "status": "processing",
        "created_at": datetime.now().isoformat(),
        "article_styles": request.article_styles,
        "progress": 0
    }
    
    task_storage[task_id] = task_info
    
    # å¯åŠ¨åå°å¤„ç†
    asyncio.create_task(process_article_generation(task_id, request.stock_code, request.article_styles))
    
    logger.info(f"âœ… æ–‡ç« ç”Ÿæˆä»»åŠ¡å·²åˆ›å»º: {task_id} for {request.stock_code}")
    
    return TaskResponse(
        task_id=task_id,
        status="pending",
        message=f"è‚¡ç¥¨ {request.stock_code} çš„æ–‡ç« ç”Ÿæˆä»»åŠ¡å·²å¯åŠ¨"
    )

async def process_article_generation(task_id: str, stock_code: str, styles: List[str]):
    """åå°å¤„ç†æ–‡ç« ç”Ÿæˆ"""
    try:
        # æ›´æ–°è¿›åº¦
        task_storage[task_id]["progress"] = 20
        task_storage[task_id]["status"] = "collecting_data"
        
        # æ¨¡æ‹Ÿè·å–è‚¡ç¥¨æ•°æ® (1ç§’)
        await asyncio.sleep(1)
        
        task_storage[task_id]["progress"] = 50
        task_storage[task_id]["status"] = "ai_analyzing"
        
        # æ¨¡æ‹ŸAIåˆ†æå¤„ç† (2ç§’)
        await asyncio.sleep(2)
        
        task_storage[task_id]["progress"] = 80
        task_storage[task_id]["status"] = "generating_articles"
        
        # ç”Ÿæˆæ–‡ç« 
        articles = []
        for i, style in enumerate(styles):
            # è°ƒç”¨AIåˆ†ææ¥å£è·å–å†…å®¹
            analysis = await ai_analyze_stock(stock_code, style)
            
            article = {
                "id": f"article_{i+1}",
                "style": style,
                "title": analysis["title"],
                "content": analysis["content"],
                "summary": analysis["summary"],
                "recommendations": analysis["recommendations"],
                "confidence_score": analysis["confidence_score"],
                "word_count": len(analysis["content"]),
                "generated_at": datetime.now().isoformat()
            }
            articles.append(article)
        
        await asyncio.sleep(1)
        
        # å®Œæˆä»»åŠ¡
        result = {
            "task_id": task_id,
            "stock_code": stock_code,
            "articles": articles,
            "metadata": {
                "total_articles": len(articles),
                "processing_time": datetime.now().isoformat(),
                "styles_processed": styles
            },
            "status": "completed"
        }
        
        task_storage[task_id].update(result)
        task_storage[task_id]["progress"] = 100
        task_storage[task_id]["completed_at"] = datetime.now().isoformat()
        
        logger.info(f"ğŸ‰ æ–‡ç« ç”Ÿæˆä»»åŠ¡å®Œæˆ: {task_id}")
        
    except Exception as e:
        task_storage[task_id]["status"] = "failed"
        task_storage[task_id]["error"] = str(e)
        logger.error(f"âŒ ä»»åŠ¡å¤„ç†å¤±è´¥: {task_id} - {e}")

# æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
@app.get("/api/tasks/{task_id}")
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€"""
    if task_id not in task_storage:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    return task_storage[task_id]

# æ‰¹é‡å¤„ç†
@app.post("/api/batch/generate-articles")
async def batch_generate_articles(stock_codes: List[str], article_styles: Optional[List[str]] = None):
    """æ‰¹é‡ç”Ÿæˆå¤šåªè‚¡ç¥¨çš„åˆ†ææ–‡ç« """
    if len(stock_codes) > 5:
        raise HTTPException(status_code=400, detail="æ‰¹é‡å¤„ç†æœ€å¤šæ”¯æŒ5åªè‚¡ç¥¨")
    
    if not article_styles:
        article_styles = ["professional", "optimistic"]
    
    task_ids = []
    for stock_code in stock_codes:
        request = ArticleRequest(stock_code=stock_code, article_styles=article_styles)
        task_response = await generate_articles(request)
        task_ids.append({
            "stock_code": stock_code,
            "task_id": task_response.task_id
        })
    
    logger.info(f"âœ… æ‰¹é‡ä»»åŠ¡åˆ›å»ºå®Œæˆ: {len(task_ids)} ä¸ªä»»åŠ¡")
    
    return {
        "message": f"å·²åˆ›å»º {len(task_ids)} ä¸ªæ–‡ç« ç”Ÿæˆä»»åŠ¡",
        "tasks": task_ids
    }

# ç³»ç»Ÿç»Ÿè®¡
@app.get("/api/system/stats")
async def get_system_stats():
    """è·å–ç³»ç»Ÿè¿è¡Œç»Ÿè®¡ä¿¡æ¯"""
    completed_tasks = sum(1 for task in task_storage.values() if task.get("status") == "completed")
    running_tasks = sum(1 for task in task_storage.values() if task.get("status") in ["processing", "pending"])
    failed_tasks = sum(1 for task in task_storage.values() if task.get("status") == "failed")
    
    return {
        "system": {
            "uptime": datetime.now().isoformat(),
            "version": "1.0.0"
        },
        "tasks": {
            "total_tasks": len(task_storage),
            "completed_tasks": completed_tasks,
            "running_tasks": running_tasks,
            "failed_tasks": failed_tasks
        },
        "performance": {
            "avg_processing_time": "3.5s",
            "success_rate": f"{(completed_tasks/(len(task_storage) or 1)*100):.1f}%"
        }
    }

def get_performance_assessment(pe_ratio: float) -> str:
    """è¯„ä¼°ä¸šç»©è¡¨ç°"""
    if pe_ratio < 15:
        return "ç¨³å¥ä¸”ä¼°å€¼åä½"
    elif pe_ratio < 25:
        return "è¡¨ç°è‰¯å¥½"
    elif pe_ratio < 40:
        return "æˆé•¿æ€§è¾ƒå¥½ä½†éœ€å…³æ³¨ä¼°å€¼"
    else:
        return "é«˜æˆé•¿ä½†ä¼°å€¼åé«˜"

def get_valuation_assessment(pe_ratio: float) -> str:
    """ä¼°å€¼è¯„ä¼°"""
    if pe_ratio < 15:
        return "æ˜æ˜¾ä½ä¼°"
    elif pe_ratio < 25:
        return "åˆç†ä¼°å€¼"
    elif pe_ratio < 40:
        return "ç•¥å¾®åé«˜"
    else:
        return "æ˜æ˜¾é«˜ä¼°"

def get_investment_suggestion(pe_ratio: float, market_cap: float) -> str:
    """æŠ•èµ„å»ºè®®"""
    if pe_ratio < 20 and market_cap > 500:
        return "å€¼å¾—å…³æ³¨çš„æŠ•èµ„æ ‡çš„"
    elif pe_ratio < 30:
        return "å¯é€‚åº¦å…³æ³¨"
    else:
        return "éœ€è°¨æ…è¯„ä¼°é£é™©"

def get_risk_warning(pe_ratio: float, market_cap: float) -> str:
    """é£é™©æç¤º"""
    if pe_ratio > 40:
        return "ä¼°å€¼é£é™©è¾ƒé«˜"
    elif market_cap < 100:
        return "å°ç›˜è‚¡æ³¢åŠ¨æ€§å¤§"
    else:
        return "é£é™©ç›¸å¯¹å¯æ§"

def get_opportunity_level(pe_ratio: float, market_cap: float) -> str:
    """æœºä¼šç¨‹åº¦"""
    if pe_ratio < 20:
        return "æ˜¾è‘—"
    elif pe_ratio < 30:
        return "ä¸€èˆ¬"
    else:
        return "éœ€è°¨æ…è¯„ä¼°"

def get_conservative_advice(pe_ratio: float, market_cap: float) -> str:
    """ä¿å®ˆå»ºè®®"""
    if pe_ratio < 18 and market_cap > 300:
        return "é€‚åˆç¨³å¥æŠ•èµ„"
    elif pe_ratio < 25:
        return "å¯è€ƒè™‘å°ä»“ä½"
    else:
        return "å»ºè®®è§‚æœ›ä¸ºä¸»"

def get_recommendations(pe_ratio: float, market_cap: float, style: str) -> List[str]:
    """è·å–æŠ•èµ„å»ºè®®"""
    base_recommendations = [
        "å¯†åˆ‡å…³æ³¨å¸‚åœºåŠ¨æ€",
        "æ§åˆ¶æŠ•èµ„ä»“ä½æ¯”ä¾‹",
        "è®¾ç½®åˆç†æ­¢ç›ˆæ­¢æŸç‚¹"
    ]
    
    if style == "professional":
        base_recommendations.append("å…³æ³¨å…¬å¸åŸºæœ¬é¢å˜åŒ–")
        if pe_ratio > 30:
            base_recommendations.append("æ³¨æ„ä¼°å€¼é£é™©")
    elif style == "dark":
        base_recommendations.extend(["é˜²èŒƒæœºæ„å‰²éŸ­èœ", "ä¿æŒç†æ€§ï¼Œé¿å…è¿½æ¶¨æ€è·Œ"])
    elif style == "optimistic":
        base_recommendations.extend(["æŠ“ä½å¸‚åœºæœºé‡", "é€‚å½“å¢åŠ é…ç½®æ¯”ä¾‹"])
    elif style == "conservative":
        base_recommendations.extend(["åˆ†æ•£æŠ•èµ„é™ä½é£é™©", "é•¿æœŸæŒæœ‰ç­–ç•¥"])
    
    return base_recommendations

def get_risk_level(pe_ratio: float, market_cap: float) -> str:
    """é£é™©è¯„çº§"""
    if pe_ratio > 40 or market_cap < 50:
        return "high"
    elif pe_ratio > 25 or market_cap < 200:
        return "medium"
    else:
        return "low"

def determine_trend(k_data: List[Dict]) -> str:
    """åŸºäºè¿‘æœŸKçº¿æ•°æ®åˆ¤æ–­è¶‹åŠ¿"""
    if not k_data or len(k_data) < 3:
        return "æ•°æ®ä¸è¶³"
    
    # ç®€å•çš„è¶‹åŠ¿åˆ¤æ–­é€»è¾‘
    recent_closes = [float(k.get("æ”¶ç›˜", 0)) for k in k_data[-5:]]
    if len(recent_closes) < 3:
        return "è¶‹åŠ¿æœªæ˜"
    
    # è®¡ç®—è¶‹åŠ¿
    up_days = sum(1 for i in range(1, len(recent_closes)) if recent_closes[i] > recent_closes[i-1])
    down_days = sum(1 for i in range(1, len(recent_closes)) if recent_closes[i] < recent_closes[i-1])
    
    if up_days > down_days + 1:
        return "ä¸Šå‡è¶‹åŠ¿"
    elif down_days > up_days + 1:
        return "ä¸‹è·Œè¶‹åŠ¿"
    else:
        return "éœ‡è¡è¶‹åŠ¿"

def format_large_number(num):
    """æ ¼å¼åŒ–å¤§æ•°å­—"""
    if not num or num == 0:
        return "0"
    
    if abs(num) >= 100000000:  # äº¿
        return f"{num/100000000:.2f}äº¿"
    elif abs(num) >= 10000:  # ä¸‡
        return f"{num/10000:.2f}ä¸‡"
    else:
        return f"{num:.2f}"

if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ å¯åŠ¨Prismæµ‹è¯•æœåŠ¡å™¨ (ä½¿ç”¨çœŸå®è‚¡ç¥¨æ•°æ®å®Œæ•´ç‰ˆ)...")
    uvicorn.run(app, host="0.0.0.0", port=3006, log_level="info")